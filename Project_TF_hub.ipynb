{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_TF_hub.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkdoyun/google_colab/blob/master/Project_TF_hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TGo4w-1Q98G"
      },
      "source": [
        "# TF-HUB 함수 이용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC3JvmVny0_c",
        "outputId": "c934ef7f-e5b3-4b47-ed17-37a5740f83ed"
      },
      "source": [
        "# ctrl+f9 -> 모두 실행\n",
        "# ctrl+f10 -> 이후 셀 실행\n",
        "\n",
        "# google 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrDuyFGQTCPG",
        "outputId": "a9f0858d-855a-4493-9204-d8f3d62fcd75"
      },
      "source": [
        "pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 100.1 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=74140c1cc13f93d4f320078c127f817381cd7cf270bc0b45a814ced90ef5a7db\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q76Njp0F9Zm7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "e1717ab9-a6d3-4843-9fcf-74be14ba424f"
      },
      "source": [
        "# 웹캠 사진 출력 함수 take_photo()\n",
        "# 캡처 버튼 누르면 -> 'photo.jpg'로 저장\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n",
        "# 웹캠으로 사진 찍어서 얼굴 부분만 크롭\n",
        "# 해당 이미지 저장하기 (photo_trim.jpg)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 사진 찍기\n",
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))\n",
        "\n",
        "# 사진에 네모박스 치기\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "\n",
        "img1 = face_recognition.load_image_file('photo.jpg')\n",
        "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# face_recognition이 검출한 얼굴의 위치 가져옴\n",
        "# 한 이미지에 사람 많다면 각 구역에 대한 위치 반환\n",
        "\n",
        "faceLoc = face_recognition.face_locations(img1)[0]\n",
        "encodeImg1 = face_recognition.face_encodings(img1)[0] # 얼굴 구역 내 세밀한 특징 인코딩\n",
        "# 특징 많이 보유 -> 그 사람이라 판단, 다른 사진들도 학습 & 예측 가능\n",
        "# cv2.rectangle(img1, (faceLoc[3], faceLoc[0]), (faceLoc[1], faceLoc[2]), (255, 0, 255), 2) # 사각형 얼굴에 표시\n",
        "# cv2.rectangle(사진, start_point(시작점 x, y), end_point, color, thickness)\n",
        "\n",
        "\n",
        "# 이미지 얼굴 부분 자르고 따로 저장\n",
        "x = faceLoc[3]; y = faceLoc[0] # 자르고 싶은 지점의 x좌표, y좌표\n",
        "w = abs(faceLoc[1]-faceLoc[3]); h = abs(faceLoc[2]-faceLoc[0]) # x로부터 width, y로부터 height 지정\n",
        "\n",
        "# 크롭 범위 확대\n",
        "# x = int(x / 1.8); y = int(y / 1.8)\n",
        "# w = int(w * 1.8); h = int(h * 1.8)\n",
        "\n",
        "img_trim = img1[y:y + h, x:x+w] # trim한 결과를 img_trim에 넣는다\n",
        "cv2.imwrite('photo_trim.jpg', img_trim) # 저장\n",
        "\n",
        "#img_trim = cv2.imread('photo_trim.jpg', cv2.IMREAD_GRAYSCALE) # 흑백 처리해서 다시 불러옴\n",
        "cv2_imshow(img_trim) # display\n",
        "\n",
        "#cv2.imwrite('photo_trim.jpg', img_trim) # 흑백으로 다시 저장\n",
        "\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3102ebf749bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/face_recognition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_face_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_landmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcnn_face_detection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detector_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_face_detection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mface_recognition_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_recognition_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-wheel-mmuzni47/dlib/dlib/cuda/gpu_data.cpp:201. code: 100, reason: no CUDA-capable device is detected"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAbroqZPSGo4"
      },
      "source": [
        "# set up\n",
        "# 오른쪽의 스타일 유형 설정 후 코드 실행\n",
        "# 설정\n",
        "# import tf2 and all relevant dependencies\n",
        "\n",
        "import functools\n",
        "import os\n",
        "\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import PIL.Image\n",
        "\n",
        "# print(\"TF Version: \", tf.__version__)\n",
        "# print(\"TF Hub version: \", hub.__version__)\n",
        "# print(\"Eager mode enabled: \", tf.executing_eagerly())\n",
        "# print(\"GPU available: \", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# define image loading, saving and visualization functions\n",
        "# 함수 정의\n",
        "\n",
        "def crop_center(image):\n",
        "  \"\"\"Returns a cropped square image.\"\"\"\n",
        "  shape = image.shape\n",
        "  new_shape = min(shape[1], shape[2])\n",
        "  offset_y = max(shape[1] - shape[2], 0) // 2\n",
        "  offset_x = max(shape[2] - shape[1], 0) // 2\n",
        "  image = tf.image.crop_to_bounding_box(\n",
        "      image, offset_y, offset_x, new_shape, new_shape)\n",
        "  return image\n",
        "\n",
        "def load_img(path_to_img):\n",
        "  max_dim = 512\n",
        "  img = tf.io.read_file(path_to_img)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "  shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "  long_dim = max(shape)\n",
        "  scale = max_dim / long_dim\n",
        "\n",
        "  new_shape = tf.cast(shape * scale, tf.int32)\n",
        "\n",
        "  img = tf.image.resize(img, new_shape)\n",
        "  img = img[tf.newaxis, :]\n",
        "  return img\n",
        "\n",
        "def show_n(images, titles=('',)):\n",
        "  n = len(images)\n",
        "  image_sizes = [image.shape[1] for image in images]\n",
        "  w = (image_sizes[0] * 6) // 320\n",
        "  plt.figure(figsize=(w * n, w))\n",
        "  gs = gridspec.GridSpec(1, n, width_ratios=image_sizes)\n",
        "  for i in range(n):\n",
        "    plt.subplot(gs[i])\n",
        "    plt.imshow(images[i][0], aspect='equal')\n",
        "    plt.axis('off')\n",
        "    plt.title(titles[i] if len(titles) > i else '')\n",
        "  plt.show()\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "  tensor = tensor*255\n",
        "  tensor = np.array(tensor, dtype=np.uint8)\n",
        "  if np.ndim(tensor)>3:\n",
        "    assert tensor.shape[0] == 1\n",
        "    tensor = tensor[0]\n",
        "  return PIL.Image.fromarray(tensor)\n",
        "\n",
        "#@title 스타일 유형 { form-width: \"30%\" }\n",
        "style_type = \"1. Gogh\" #@param [\"1. Gogh\", \"2. Kandinsky\", \"3. LeeJungSeop\", \"4. Matisse\", \"5. Monet\", \"6. Picasso\", \"7. ChunKyungJa\", \"8. Sketch\"]\n",
        "\n",
        "# load image\n",
        "\n",
        "content_image_url = 'photo_trim.jpg' # 크롭 후 생성한 사진\n",
        "style_type_num = style_type[0]\n",
        "\n",
        "# 스타일 유형 선택 -> 1 ~ 8 중 선택\n",
        "if style_type_num == '1': # Gogh\n",
        "  style_image_url = '/content/drive/MyDrive/Colab_Notebooks/styles/style_Gogh.jpeg' # 스타일\n",
        "elif style_type_num == '2': # Kandinsky\n",
        "  style_image_url = '/content/drive/MyDrive/Colab_Notebooks/styles/style_Kandinsky.jpeg' # 스타일\n",
        "elif style_type_num == '3': # LeeJungSeop\n",
        "  style_image_url = '/content/drive/MyDrive/Colab_Notebooks/styles/style_LeeJungSeop.jpg' # 스타일\n",
        "elif style_type_num == '4': # Matisse\n",
        "  style_image_url = '/content/drive/MyDrive/Colab_Notebooks/styles/style_Matisse.jpg' # 스타일\n",
        "elif style_type_num == '5': # Monet\n",
        "  style_image_url = '/content/drive/MyDrive/Colab_Notebooks/styles/style_Monet.jpeg' # 스타일\n",
        "elif style_type_num == '6': # Picasso\n",
        "  style_image_url = '/content/drive/MyDrive/Colab_Notebooks/styles/style_Picasso.jpeg' # 스타일\n",
        "elif style_type_num == '7': # ChunKyungJa\n",
        "  style_image_url = '/content/drive/MyDrive/Colab_Notebooks/styles/style_ChunKyungJa.jpg' # 스타일\n",
        "else: # 8 Sketch\n",
        "  style_image_url = '/content/drive/MyDrive/Colab_Notebooks/drawing2.jpg' # 스타일\n",
        "\n",
        "output_image_size = 384\n",
        "\n",
        "# The content image size can be arbitrary.\n",
        "content_img_size = (output_image_size, output_image_size)\n",
        "# The style prediction model was trained with image size 256 and it's the \n",
        "# recommended image size for the style image (though, other sizes work as \n",
        "# well but will lead to different results).\n",
        "style_img_size = (256, 256)  # Recommended to keep it at 256.\n",
        "\n",
        "content_image = load_img(content_image_url)\n",
        "style_image = load_img(style_image_url)\n",
        "style_image = tf.nn.avg_pool(style_image, ksize=[3,3], strides=[1,1], padding='SAME')\n",
        "\n",
        "# import TF Hub module\n",
        "hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n",
        "hub_module = hub.load(hub_handle)\n",
        "\n",
        "# Stylize content image with given style image.\n",
        "# This is pretty fast within a few milliseconds on a GPU.\n",
        "\n",
        "outputs = hub_module(tf.constant(content_image), tf.constant(style_image))\n",
        "stylized_image = outputs[0]\n",
        "\n",
        "# Visualize input images and the generated stylized image.\n",
        "\n",
        "show_n([content_image, style_image, stylized_image], titles=['Original content image', 'Style image', 'Stylized image'])\n",
        "\n",
        "tensor_to_image(stylized_image).save('stylized_photo.jpg') # 결과물 저장\n",
        "\n",
        "# PC에 저장\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('stylized_photo.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}