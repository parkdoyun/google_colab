{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice_pdy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkdoyun/google_colab/blob/master/practice_pdy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhCr23RR0pbb",
        "outputId": "9f75b0cd-41a5-4b52-c0c5-3d286aae28af"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfp_X6ax1_07",
        "outputId": "b1b7acd7-1218-43fd-f031-3797cf618502"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  x = torch.empty(5, 3)\n",
        "  y = torch.ones_like(x, device=device)\n",
        "  x = x.to(device)\n",
        "  z = x * y\n",
        "  print(z)\n",
        "  print(z.to('cpu', torch.double))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 7.1166e+10,  3.0928e-41,  1.7096e-43],\n",
            "        [ 4.4842e-44,  8.5479e-44,  4.4842e-44],\n",
            "        [ 1.6816e-43,  4.4842e-44,  5.8855e-44],\n",
            "        [ 4.4842e-44,  1.6956e-43,  7.1846e+22],\n",
            "        [ 9.2198e-39,  7.0374e+22, -1.3625e+37]], device='cuda:0')\n",
            "tensor([[ 7.1166e+10,  3.0928e-41,  1.7096e-43],\n",
            "        [ 4.4842e-44,  8.5479e-44,  4.4842e-44],\n",
            "        [ 1.6816e-43,  4.4842e-44,  5.8855e-44],\n",
            "        [ 4.4842e-44,  1.6956e-43,  7.1846e+22],\n",
            "        [ 9.2198e-39,  7.0374e+22, -1.3625e+37]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4LS76595DJU",
        "outputId": "94779dd9-3b2c-4e96-eb9d-8373bbbfe3b2"
      },
      "source": [
        "# CNN 이용한 Fashion MNIST 데이터 학습시키기 연습\n",
        "# CNN 이용해서 의류 관련 데이터 학습 -> 최종 의류 데이터 분류\n",
        "# 1. Fashion MNIST data load하기\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un9kek1K4rJ2"
      },
      "source": [
        "# 2. 간단 CNN 모델 구현\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.25))  \n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(256))\n",
        "  model.add(tf.keras.layers.Activation('elu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(10))\n",
        "  model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd-skf4d7yWJ",
        "outputId": "026b23d1-a37a-4e16-8a90-7b0a9af4922d"
      },
      "source": [
        "# 3. model 학습\n",
        "import os\n",
        "\n",
        "model = create_model()\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "    epochs=17, # 17번의 epoch 동안 학습 진행\n",
        "    steps_per_epoch=60,\n",
        "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "    validation_freq=17\n",
        ")\n",
        "\n",
        "model.save_weights('./fashion_mnist.h5', overwrite=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "60/60 [==============================] - 46s 231ms/step - loss: 1.1929 - sparse_categorical_accuracy: 0.6806\n",
            "Epoch 2/17\n",
            "60/60 [==============================] - 14s 230ms/step - loss: 0.5301 - sparse_categorical_accuracy: 0.8205\n",
            "Epoch 3/17\n",
            "60/60 [==============================] - 14s 230ms/step - loss: 0.4441 - sparse_categorical_accuracy: 0.8465\n",
            "Epoch 4/17\n",
            "60/60 [==============================] - 14s 230ms/step - loss: 0.3868 - sparse_categorical_accuracy: 0.8640\n",
            "Epoch 5/17\n",
            "60/60 [==============================] - 14s 230ms/step - loss: 0.3471 - sparse_categorical_accuracy: 0.8779\n",
            "Epoch 6/17\n",
            "60/60 [==============================] - 14s 229ms/step - loss: 0.3168 - sparse_categorical_accuracy: 0.8870\n",
            "Epoch 7/17\n",
            "60/60 [==============================] - 14s 230ms/step - loss: 0.2894 - sparse_categorical_accuracy: 0.8974\n",
            "Epoch 8/17\n",
            "60/60 [==============================] - 14s 229ms/step - loss: 0.2704 - sparse_categorical_accuracy: 0.9022\n",
            "Epoch 9/17\n",
            "60/60 [==============================] - 14s 229ms/step - loss: 0.2543 - sparse_categorical_accuracy: 0.9062\n",
            "Epoch 10/17\n",
            "60/60 [==============================] - 14s 229ms/step - loss: 0.2333 - sparse_categorical_accuracy: 0.9144\n",
            "Epoch 11/17\n",
            "60/60 [==============================] - 14s 229ms/step - loss: 0.2254 - sparse_categorical_accuracy: 0.9179\n",
            "Epoch 12/17\n",
            "60/60 [==============================] - 14s 229ms/step - loss: 0.2071 - sparse_categorical_accuracy: 0.9237\n",
            "Epoch 13/17\n",
            "60/60 [==============================] - 14s 229ms/step - loss: 0.1985 - sparse_categorical_accuracy: 0.9266\n",
            "Epoch 14/17\n",
            "60/60 [==============================] - 14s 230ms/step - loss: 0.1858 - sparse_categorical_accuracy: 0.9320\n",
            "Epoch 15/17\n",
            "60/60 [==============================] - 14s 229ms/step - loss: 0.1715 - sparse_categorical_accuracy: 0.9359\n",
            "Epoch 16/17\n",
            "60/60 [==============================] - 14s 230ms/step - loss: 0.1679 - sparse_categorical_accuracy: 0.9379\n",
            "Epoch 17/17\n",
            "60/60 [==============================] - 17s 276ms/step - loss: 0.1611 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.2432 - val_sparse_categorical_accuracy: 0.9201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlMHTMAh9k0Q"
      },
      "source": [
        "# 4. test\n",
        "from matplotlib import pyplot\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_predictions(images, predictions):\n",
        "  n = images.shape[0]\n",
        "  nc = int(np.ceil(n/4))\n",
        "  f, axes = pyplot.subplots(nc, 4)\n",
        "  for i in range(nc * 4):\n",
        "    y = i // 4\n",
        "    x = i % 4\n",
        "    axes [x, y].axis('off')\n",
        "\n",
        "    label = LABEL_NAMES[np.argmax(predictions[i])]\n",
        "    confidence = np.max(predictions[i])\n",
        "\n",
        "    if i > n:\n",
        "      continue\n",
        "    axes[x, y].imshow(images[i])\n",
        "    axes[x,y].text(0.5, 0.5, label + '\\n%.3f' % confidence, fontsize = 14)\n",
        "\n",
        "  pyplot.gcf().set_size_inches(8, 8)\n",
        "\n",
        "LABEL_NAMES = ['t_shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boots']\n",
        "\n",
        "cpu_model = create_model()\n",
        "cpu_model.load_weights('./fashion_mnist.h5')\n",
        "\n",
        "plot_predictions(np.squeeze(x_test[:16]),\n",
        "                 cpu_model.predict(x_test[:16]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg5Wu06j9tZw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}